# -*- coding: utf-8 -*-
"""TrustscoreShap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m-Qmkz2NRiyCbJ31nTmTjZIabPsq926b
"""

# -*- coding: utf-8 -*-
"""Trustscore v2 with SHAP.ipynb
Automatically generated and SHAP-enhanced for Colab.
"""

!pip install shap

# ========== 🔁 IMPORTS ========== #
import pandas as pd
import shap
import joblib
import numpy as np

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import files

from trustscore_batch_analyzer import TrustScoreAnalyzer, create_sample_data

# ========== 🛠️ GENERATE DATA ========== #
df = create_sample_data(5000)
print(f"✅ Generated dataset with shape: {df.shape}")
df.to_csv("generated_trustscore_data.csv", index=False)
print("💾 Dataset saved to generated_trustscore_data.csv")

# ========== 🔍 RUN TRUSTSCORE ANALYZER ========== #
analyzer = TrustScoreAnalyzer()
results_df = analyzer.analyze_batch(df)
summary = analyzer.generate_summary_report(results_df)

print("\n=== 🔍 ANALYSIS SUMMARY ===")
print(f"📊 Total Records Processed: {summary['total_records']}")
print(f"✅ Overall Approval Rate: {summary['approval_rate']:.1f}%")
print(f"⚠️ High Risk Applications: {summary['high_risk_count']}")

print("\n=== 📂 DECISION BREAKDOWN ===")
for decision, count in summary['decision_distribution'].items():
    percentage = summary['decision_percentages'][decision]
    print(f"  {decision}: {count} ({percentage}%)")

print("\n=== 📈 SCORE STATISTICS ===")
score_stats = summary['score_statistics']['overall_score']
print(f"  Average Score: {score_stats['mean']:.1f}")
print(f"  Score Range: {score_stats['min']:.0f} - {score_stats['max']:.0f}")

print("\nTop 5 Highest Scores:")
display(results_df.nlargest(5, 'overall_score')[['overall_score', 'decision', 'risk_category', 'income', 'credit_score']])

print("Top 5 Lowest Scores:")
display(results_df.nsmallest(5, 'overall_score')[['overall_score', 'decision', 'risk_category', 'income', 'credit_score']])

print("\n📊 Generating visualizations...")
analyzer.create_visualizations(results_df)

results_df.to_csv("trustscore_results_5000.csv", index=False)
print("💾 Results saved to trustscore_results_5000.csv")
files.download("trustscore_results_5000.csv")

# ========== 🤖 TRAIN MODEL ========== #
features = [
    'income', 'credit_score', 'loan_amount', 'loan_term', 'age', 'monthly_debt',
    'employment', 'loan_purpose', 'gender', 'residence'
]

X = pd.get_dummies(results_df[features], drop_first=True)
y = results_df['decision']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_model.fit(X_train, y_train)

print("✅ Retrained Classification Report:\n")
print(classification_report(y_test, rf_model.predict(X_test)))

print("\n📉 Confusion Matrix:")
print(confusion_matrix(y_test, rf_model.predict(X_test)))

# ========== 💾 EXPORT MODEL ========== #
model_path = "trustscore_rf_model_5000.pkl"
joblib.dump(rf_model, model_path)
print(f"💾 Model saved to {model_path}")
files.download(model_path)

# ========== 🔮 SAMPLE PREDICTIONS ========== #
df_new = create_sample_data(5)
df_new_encoded = pd.get_dummies(df_new[features], drop_first=True)
df_new_encoded = df_new_encoded.reindex(columns=X.columns, fill_value=0)
new_predictions = rf_model.predict(df_new_encoded)
df_new['predicted_decision'] = new_predictions
print("\n🔮 New Predictions:")
print(df_new[['income', 'credit_score', 'loan_amount', 'employment', 'loan_purpose', 'predicted_decision']])

# ========== 🔍 SHAP EXPLAINABILITY ========== #
print("
🔍 SHAP Analysis Starting...")
shap.initjs()

# Sample 5 instances
sample = X_test.iloc[:5]

# SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(sample)

target_index = 1 if len(shap_values) > 1 else 0

# Use HTML-based force plot (Colab-friendly)
shap_html = shap.force_plot(
    explainer.expected_value[target_index],
    shap_values[target_index][0, :],
    sample.iloc[0, :],
    feature_names=sample.columns.tolist(),
    show=False
)
from IPython.core.display import display, HTML
display(HTML(shap_html.html()))

# Print human-readable SHAP explanations
print("
🧠 SHAP Explanation in Words:")
for i in range(len(sample)):
    print(f"
📌 Sample #{i+1} prediction: {rf_model.predict([sample.iloc[i]])[0]}")
    shap_values_i = shap_values[target_index][i]
    top_features = np.argsort(-np.abs(shap_values_i))[:3]
    print("Top features driving the prediction:")
    for j in top_features:
        feature_name = sample.columns[j]
        impact = shap_values_i[j]
        direction = "increased" if impact > 0 else "decreased"
        print(f" - {feature_name} {direction} the likelihood of approval by {abs(impact):.4f}")

# SHAP Summary Plot

except Exception as e:
    print("⚠️ Failed to render summary plot:", e)
try:
    print("
📊 SHAP Summary Plot:")
    shap.summary_plot(shap_values[target_index], sample, feature_names=sample.columns.tolist())
except Exception as e:
    print("⚠️ Failed to render summary plot:", e)

# -*- coding: utf-8 -*-
"""Trustscore v2 with SHAP.ipynb
Automatically generated and SHAP-enhanced for Colab.
"""

!pip install shap

# ========== 🔁 IMPORTS ========== #
import pandas as pd
import shap
import joblib
import numpy as np

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import files

from trustscore_batch_analyzer import TrustScoreAnalyzer, create_sample_data

# ========== 🛠️ GENERATE DATA ========== #
df = create_sample_data(5000)
print(f"✅ Generated dataset with shape: {df.shape}")
df.to_csv("generated_trustscore_data.csv", index=False)
print("💾 Dataset saved to generated_trustscore_data.csv")

# ========== 🔍 RUN TRUSTSCORE ANALYZER ========== #
analyzer = TrustScoreAnalyzer()
results_df = analyzer.analyze_batch(df)
summary = analyzer.generate_summary_report(results_df)

print("\n=== 🔍 ANALYSIS SUMMARY ===")
print(f"📊 Total Records Processed: {summary['total_records']}")
print(f"✅ Overall Approval Rate: {summary['approval_rate']:.1f}%")
print(f"⚠️ High Risk Applications: {summary['high_risk_count']}")

print("\n=== 📂 DECISION BREAKDOWN ===")
for decision, count in summary['decision_distribution'].items():
    percentage = summary['decision_percentages'][decision]
    print(f"  {decision}: {count} ({percentage}%)")

print("\n=== 📈 SCORE STATISTICS ===")
score_stats = summary['score_statistics']['overall_score']
print(f"  Average Score: {score_stats['mean']:.1f}")
print(f"  Score Range: {score_stats['min']:.0f} - {score_stats['max']:.0f}")

print("\nTop 5 Highest Scores:")
display(results_df.nlargest(5, 'overall_score')[['overall_score', 'decision', 'risk_category', 'income', 'credit_score']])

print("Top 5 Lowest Scores:")
display(results_df.nsmallest(5, 'overall_score')[['overall_score', 'decision', 'risk_category', 'income', 'credit_score']])

print("\n📊 Generating visualizations...")
analyzer.create_visualizations(results_df)

results_df.to_csv("trustscore_results_5000.csv", index=False)
print("💾 Results saved to trustscore_results_5000.csv")
files.download("trustscore_results_5000.csv")

# ========== 🤖 TRAIN MODEL ========== #
features = [
    'income', 'credit_score', 'loan_amount', 'loan_term', 'age', 'monthly_debt',
    'employment', 'loan_purpose', 'gender', 'residence'
]

X = pd.get_dummies(results_df[features], drop_first=True)
y = results_df['decision']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_model.fit(X_train, y_train)

print("✅ Retrained Classification Report:\n")
print(classification_report(y_test, rf_model.predict(X_test)))

print("\n📉 Confusion Matrix:")
print(confusion_matrix(y_test, rf_model.predict(X_test)))

# ========== 💾 EXPORT MODEL ========== #
model_path = "trustscore_rf_model_5000.pkl"
joblib.dump(rf_model, model_path)
print(f"💾 Model saved to {model_path}")
files.download(model_path)

# ========== 🔮 SAMPLE PREDICTIONS ========== #
df_new = create_sample_data(5)
df_new_encoded = pd.get_dummies(df_new[features], drop_first=True)
df_new_encoded = df_new_encoded.reindex(columns=X.columns, fill_value=0)
new_predictions = rf_model.predict(df_new_encoded)
df_new['predicted_decision'] = new_predictions
print("\n🔮 New Predictions:")
print(df_new[['income', 'credit_score', 'loan_amount', 'employment', 'loan_purpose', 'predicted_decision']])

# ========== 🔍 SHAP EXPLAINABILITY ========== #
print("\n🔍 SHAP Analysis Starting...")
shap.initjs()

# Sample 5 instances
sample = X_test.iloc[:5].reindex(columns=X.columns, fill_value=0)

# SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(sample)

# Visualize first sample
shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], sample.iloc[0, :], matplotlib=True)

# Print human-readable SHAP explanations
print("\n🧠 SHAP Explanation in Words:")
for i in range(len(sample)):
    print(f"\n📌 Sample #{i+1} prediction: {rf_model.predict([sample.iloc[i]])[0]}")
    shap_values_i = shap_values[1][i]
    top_features = np.argsort(-np.abs(shap_values_i))[:3]
    print("Top features driving the prediction:")
    for j in top_features:
        feature_name = sample.columns[j]
        impact = shap_values_i[j]
        direction = "increased" if impact > 0 else "decreased"
        print(f" - {feature_name} {direction} the likelihood of approval by {abs(impact):.4f}")

# Optional: SHAP Summary Plot
# print("\n📊 SHAP Summary Plot:")
# shap.summary_plot(shap_values[1], sample, feature_names=sample.columns)